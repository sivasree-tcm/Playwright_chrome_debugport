{
  "filename": "Ai_PYTHON.docx",
  "fileType": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
  "extension": "docx",
  "size": 635514,
  "lastModified": "2025-09-25T05:40:09.284Z",
  "extractedAt": "2025-11-27T10:27:11.620Z",
  "data": {
    "type": "unstructured_text",
    "lineCount": 909,
    "content": "\n\nCourse Name: AI Python for Beginners\n\nIntroduction to Python\n\nPython is one of the most popular programming languages in the world. It‚Äôs known for:\n\nA large and supportive developer community\n\nBeing used in many fields, including:\n\nSelf-driving cars\n\nChatbots\n\nSmart agriculture\n\nApplications and software development\n\nPython is also widely used in AI, making it ideal for projects like the ones you‚Äôre building.\n\n\n\nData in Python\n\nStrings\n\nStrings are used to store text. Python supports:\n\nSingle-line strings ‚Üí Enclosed in single (') or double (\") quotes\n\nMulti-line strings ‚Üí Enclosed in triple single (''') or triple double (\"\"\") quotes\n\nMain difference:\n\nSingle-line string ‚Üí Written in one line\n\nMulti-line string ‚Üí Written across multiple lines\n\nExample:\n\nsingle_line = \"Hello, Python!\"\n\nmulti_line = \"\"\"This is a \n\nmulti-line string\n\nin Python.\"\"\"\n\n\n\nNumbers\n\nPython supports different types of numbers:\n\nIntegers ‚Üí Whole numbers, e.g., 5, -3\n\nFloats ‚Üí Decimal numbers, e.g., 3.14, -0.001\n\nBooleans ‚Üí True/False values, e.g., True, False\n\n\n\nBasic Functions for Data\n\ntype() ‚Üí Tells the type of data\n\nprint() ‚Üí Displays value/output on screen\n\n\n\nF-Strings (Formatted Strings)\n\nF-strings let you insert variables or expressions directly into a string using {}.\n\nExamples:\n\na = 10\n\nb = 20\n\nprint(f\"The addition of a + b is {a+b}\")  # Output: The addition of a + b is 30\n\n\n\npi = 3.14159\n\nnum = 12345\n\nprint(f\"Pi: {pi:.2f}\")   # Pi: 3.14\n\nprint(f\"Number: {num:,}\") # Number: 12,345\n\nDebugging tip:\n\nage = 30\n\nprint(f\"{age=}\")  # Output: age=30\n\nHere, {variable=} automatically prints the variable name and its current value.\n\n\n\nVariables\n\nVariables are used to store data so you can reuse it later.\n\n\n\nLLM-LLM stands for Large Language Model ‚Äî a type of artificial intelligence (AI) model trained to understand and generate human-like language\n\nExamples: \n\nOpenAI GPT-3.5 / GPT-4\n\nMeta's LLaMA\n\nGoogle's PaLM\n\nhow to use a Large Language Model (LLM) in a Python program.\n\n\n\nOpenAI‚Äôs GPT-4o-mini model\n\nA .env file to keep your secret API key safe\n\nimport os\n\nimporting a built-in Python library called os.\n\nPython code talk to  computer‚Äôs environment (like reading secret keys stored in environment variables).\n\nfrom dotenv import load_dotenv\n\ntool called dotenv to load a .env file\n\nThis .env file contains secret info like your API key:\n\nOPENAI_API_KEY=your-secret-key-here It's a safe way to store sensitive info outside your main code.\n\n\n\nload_dotenv('.env', override=True)\n\nLoads the .env file.\n\noverride=True means: If there's already an environment variable, replace it with the one in .env.\n\n\n\nopenai_api_key = os.getenv('OPENAI_API_KEY')\n\ngetting the API key from the environment and saving it in a variable called openai_api_key.\n\nThis is the key that lets  code use OpenAI's servers.\n\nclient = OpenAI(api_key=openai_api_key)\n\nThis creates a client object to talk to OpenAI's services (like ChatGPT).\n\nclient to send messages and get responses from the model.\n\ndef get_llm_response(prompt: str) -> str:\n\nThis is a function. call it when  want a response from the AI.\n\npass in a prompt (your question or message), and it returns a response from the model.\n\ncompletion = client.chat.completions.create(...)\n\n sends  message to the model.\n\n give it:\n\nThe model name (gpt-4o-mini) ‚Äì a fast and cheap version of GPT-4o.\n\nA list of messages:\n\nsystem: sets the behavior of the AI (e.g., ‚ÄúBe helpful and short‚Äù)\n\nuser: the prompt you entered\n\ntemperature=0.0: means ‚Äúgive me factual, consistent answers‚Äù (no creativity)\n\nresponse = completion.choices[0].message.content\n\nThe AI might return multiple \"choices\", but we take the first one.\n\nWe get just the text of the response (not metadata).\n\nreturn response\n\nSends back the response so use it elsewhere in  program.\n\nTemperature:\n\nTemperature\n\nBehavior\n\nExample\n\n0.0\n\nVery strict and predictable\n\nAlways gives the same answer if you ask the same question\n\n0.5\n\nSomewhat creative\n\nMight say the same thing in different ways\n\n1.0\n\nVery creative and random\n\nTries new ideas, fun writing, maybe less accurate\n\n>1.0\n\nUnstable\n\nRarely used; responses can be unpredictable or strange\n\nEach message has:\n\nrole: who is speaking (system, user, or assistant)\n\ncontent: what they are saying (the actual text)\n\n\n\n\n\n\n\nWorking with LLMs\n\nPython can interact with Large Language Models (LLMs), like GPT, using helper functions.\n\nExample of a helper function:\n\nfrom helper_functions import print_llm_response\n\n\n\nprint_llm_response(\"What is the capital of France?\")\n\nAnother example with a prompt:\n\nfrom helper_functions import *\n\n\n\nname = \"san\"\n\nage = 21.345\n\nprompt = f\"Write a story about {name}. She is intelligent  and childish, age {round(age)}. Tell it in 50 words.\"\n\n\n\nres = get_llm_response(prompt)\n\nprint(res)\n\nPurpose: print_llm_response helps display the LLM output neatly.\n\nsend instructions to the LLM and get a readable response.\n\n\n\nCommon Functions in Python\n\nFunction\n\nUse Case\n\nprint()\n\nDisplay output\n\ninput()\n\nTake input from the user\n\nint()\n\nConvert to integer\n\nfloat()\n\nConvert to float\n\nstr()\n\nConvert to string\n\nbool()\n\nConvert to boolean\n\nabs()\n\nAbsolute value\n\nround()\n\nRound a number\n\npow()\n\nPower calculation\n\nsum()\n\nSum of iterable\n\nlen()\n\nLength of iterable\n\nmax()\n\nMaximum value\n\nmin()\n\nMinimum value\n\nsorted()\n\nSort items\n\ntype()\n\nGet type of object\n\nisinstance()\n\nCheck object type\n\nExamples:\n\nprint(len([1,2,3]))   # 3\n\nprint(type(10))       # <class 'int'>\n\nprint(int(\"5\"))       # 5\n\nprint(sum([1,2,3,4])) # 10\n\n\n\nModule 2:Automating Task with Python:\n\n1.List:\n\nA list is a collection that can store multiple items in a single variable.\n\nMutable\n\nOrdered\n\nSame type or different type\n\nExample:\n\n\n\nlist=[1,2,3]\n\nlist.append(4)\n\nprint(list)\n\nlist.remove(3)\n\nprint(list)\n\nprint(list[1])\n\nprint(list[-1])\n\nOutput: [1, 2, 3, 4]\n\n[1, 2, 4]\n\n2\n\n4\n\n\n\nLLM-based Text and Poetry Generation for Lists:\n\nfrom helper_functions import print_llm_response, get_llm_response\n\nflower_name=[\"rose\",\"lotus\",\"jasmine\"]\n\nprompt=f\"\"\"write a few sentence about the flowers{flower_name}and poem for each flower\"\"\"\n\nres = get_llm_response(prompt)\n\nprint(res)\n\n\n\nfrom helper_functions import print_llm_response, get_llm_response\n\nflower_name=[\"write a poem for tree\",\"write a email for manager about planned leave\",\"give content for any one freedom fighter india\"]\n\nlist=flower_name[1]\n\nprint_llm_response(list)\n\n\n\n2.For loop:\n\nA for loop is used to repeat a block of code for each item in a sequence\n\nflowers = [\"rose\", \"lotus\", \"jasmine\"]\n\nfor flower in flowers:\n\nprint(flower)\n\nLooping through string:\n\nfor char in \"work\":\n\nprint(char)\n\nOutput:\n\nW\n\nO\n\nR\n\nK\n\nRange functions:\n\nThe range() function generates a sequence of numbers.\n\nfor i in range(5):\n\nprint(i)\n\nllm with for loop:\n\n1.from helper_functions import print_llm_response, get_llm_response\n\nlist_of_tasks=[\"write a poem \",\"write a emial about task\"]\n\nfor task in list_of_tasks:\n\nprint_llm_response(task)\n\n\n\n2.from helper_functions import print_llm_response, get_llm_response\n\nlist=[\"football \",\"cricket\",\"volleyball\"]\n\nprompt=f\"\"\"decribe about the sports and marketing for this sports to join Sports:{list}\"\"\"\n\nprint(prompt)\n\nprint_llm_response(prompt)\n\n\n\n3. newlist=[]\n\nfrom helper_functions import print_llm_response, get_llm_response\n\nlist=[\"football \",\"cricket\",\"volleyball\"]\n\nprompt=f\"\"\"decribe about the sports and marketing for this sports to join Sports:{list}\"\"\"\n\ndescription=get_llm_response(prompt)\n\nnewlist.append(description)\n\nprint(newlist)\n\n\n\n3.Dictionaries:\n\nA dictionary in Python is a collection of key‚Äìvalue pairs.Each key is unique, and it maps to a value\n\n\n\nice_cream_flavors = {\n\n\"Mint Chocolate Chip\": \"Refreshing mint ice cream studded with decadent chocolate chips.\",\n\n\"Cookie Dough\": \"Vanilla ice cream loaded with chunks of chocolate chip cookie dough.\",\n\n\"Salted Caramel\": \"Sweet and salty with a smooth caramel swirl and a hint of sea salt.\"\n\n}\n\n\n\n# Print only keys\n\nprint(\" Ice Cream Flavors (Keys):\")\n\nprint(ice_cream_flavors.keys())   # dict_keys object\n\nprint(list(ice_cream_flavors.values()))  # convert to list for clean output\n\nprint(ice_cream_flavors[\"Mint Chocolate Chip\"])\n\nice_cream_flavors[\"Mint Chocolate Chip\"]=\"mint flavor is good\"\n\nprint(list(ice_cream_flavors.values()))\n\nice_cream_flavors[\"list\"]=[1,2,3]\n\nprint(ice_cream_flavors)\n\n\n\nllm with dic\n\nhigh_priority_tasks = [\n\n\"Compose a brief email to my boss explaining that I will be late for tomorrow's meeting.\",\n\n\"Create an outline for a presentation on the benefits of remote work.\"\n\n]\n\n\n\nmedium_priority_tasks = [\n\n\"Write a birthday poem for Otto, celebrating his 28th birthday.\",\n\n\"Draft a thank-you note for my neighbor Dapinder who helped water my plants while I was on vacation.\"\n\n]\n\n\n\nlow_priority_tasks = [\n\n\"Write a 300-word review of the movie 'The Arrival'.\"\n\n]\n\nprioritized_tasks = {\n\n\"high_priority\": high_priority_tasks,\n\n\"medium_priority\": medium_priority_tasks,\n\n\"low_priority\": low_priority_tasks\n\n}\n\nprint(prioritized_tasks)\n\nfor i in prioritized_tasks[\"high_priority\"]:\n\nprint_llm_response(i)\n\n\n\nBoolean:\n\nBoolean is a data type.contains true and false\n\nMainly used in conditions  and comparrsions.\n\na=True\n\ntype(A)//true\n\nb=False\n\ntype(b)//false\n\nAi make decision based on condition:\n\nfrom helper_functions import print_llm_response\n\ntask=[{\"description\":\"Write a email to manager about task completed details\",\"time\":5},{\"description\":\"Write a email to hr about task planned leave details\",\"time\":10},{\"description\":\"content for ai with python course\",\"time\":5}]\n\nfor s in task:\n\nif s[\"time\"]<5:\n\ndone=s[\"description\"]\n\nprint_llm_response(done)\n\nelse:\n\nprint_llm_response(\"motivate to complete the task daily different different give\")  \n\ndo=s[\"description\"]\n\nprint(f\"\"\"to complete the task{s[\"time\"]}time\"\"\")\n\n2. from helper_functions import print_llm_response\n\ntask=[{\"description\":\"Write a email to manager about task completed details\",\"time\":5},{\"description\":\"Write a email to hr about task planned leave details\",\"time\":10},{\"description\":\"content for ai with python course\",\"time\":5}]\n\nneed_to_do=[]\n\nfor s in task:\n\nif s[\"time\"]<5:\n\ndone=s[\"description\"]\n\nprint_llm_response(done)\n\nelse:\n\nprint_llm_response(\"motivate to complete the task daily different different give\")  \n\ndo=s[\"description\"]\n\nprint(f\"\"\"to complete the task{s[\"time\"]}time\"\"\")\n\nneed_to_do.append(s)\n\nprint(s)\n\nModule3:Working with data and spreadsheet in Ai\n\nIPython.display:\n\nIPython.display is a module that helps you display rich content (HTML, images, audio, video, Markdown, widgets, etc.) inside Jupyter Notebook or IPython shell. display() ‚Üí can show formatted text, pictures, audio, video, tables, HTML.\n\nUse Ipython for mardowna nad format:\n\nfrom helper_functions import get_llm_response\n\nfrom IPython.display import display, Markdown\n\nlist=[\"briyani\",\"Idly\",\"Icecream\"]\n\nprompt=f\"\"\"describe the recipe and how to make those integredient{list}\"\"\"\n\nget_prompt1=get_llm_response(prompt)\n\nprint(get_prompt1)\n\n\n\n\n\nOpen email in text format read mode:\n\n\n\nf = open(\"email.txt\", \"r\")\n\nemail = f.read()\n\nf.close()\n\n\n\n\"r\" ‚Üí read mode\n\nread() ‚Üí read all content as a string\n\nclose() ‚Üí close the file to free resources \n\nin this we manually need to close the file.\n\n\n\nAutomatically close the email by using with context block\n\n\n\n\n\nwith open(\"email.txt\", \"r\") as f:  # <-- start of context block\n\nemail = f.read()\n\nprint(email)\n\n# <-- end of context block, file is automatically closed\n\n\n\nInside the block:  read the file safely.\n\nAfter the block: Python automatically closes the file (f.close() happens ).\n\n\n\n\n\nFunction\n\nPurpose\n\nupload_txt_file\n\nHandles uploading or saving a text file to a folder or server. This prevents  from writing the file upload logic multiple times.\n\nlist_files_in_directory\n\nReturns a list of all files in a folder. Useful if  want to check available files, iterate over them, or display them in your app.\n\nprint_llm_response\n\nupload_txt_file()ü°™upload a fie\n\nlist_files_in_directory()__>list all files\n\n\n\nPrints the response from a large language model (LLM) in a clean, readable format. Helps separate display logic from main code.\n\n\n\n\n\n\n\nAbove three not predefined functions in python:my_project/\n\n‚îÇ\n\n‚îú‚îÄ‚îÄ main.py\n\n‚îú‚îÄ‚îÄ helper_functions.py\n\n‚îî‚îÄ‚îÄ uploads/   <-- folder we will create/use\n\nimport os\n\n\n\ndef upload_txt_file(file_path, destination):\n\n\"\"\"Copy a text file to the destination folder\"\"\"\n\nwith open(file_path, \"r\") as f:\n\ncontent = f.read()\n\nos.makedirs(destination, exist_ok=True)  # create folder if not exists\n\nwith open(os.path.join(destination, os.path.basename(file_path)), \"w\") as f2:\n\nf2.write(content)\n\nprint(f\"{file_path} uploaded to {destination}\")\n\n\n\ndef list_files_in_directory(folder):\n\n\"\"\"Return a list of all files in the folder\"\"\"\n\nreturn os.listdir(folder)\n\n\n\ndef print_llm_response(response):\n\n\"\"\"Print LLM response nicely\"\"\"\n\nprint(\"\\nLLM Response:\\n\" + response + \"\\n\")\n\n\n\nmain.py(locally run this file)\n\nfrom helper_functions import upload_txt_file, list_files_in_directory, print_llm_response\n\nimport os\n\n\n\n# 1Ô∏è‚É£ Create folder 'uploads' (if not exists)\n\nos.makedirs(\"uploads\", exist_ok=True)\n\n\n\n# 2Ô∏è‚É£ Make sure a file exists to upload (create one manually for test)\n\n# Example: create 'email.txt' in your project folder with some text\n\n\n\n# 3Ô∏è‚É£ Upload file to 'uploads'\n\nupload_txt_file(\"email.txt\", \"uploads\")  # email.txt must exist in your project folder\n\n\n\n# 4Ô∏è‚É£ List all files in 'uploads'\n\nfiles = list_files_in_directory(\"uploads\")\n\nprint(\"Files in folder:\", files)\n\n\n\n# 5Ô∏è‚É£ Print an LLM-style response\n\nllm_response = f\"{files[0]} successfully uploaded and listed in the folder.\"\n\nprint_llm_response(llm_response)\n\n\n\n\n\nfrom helper_functions import get_llm_response, print_llm_response\n\nf = open(\"cape_town.txt\", \"r\")\n\njournal_cape_town = f.read()\n\nf.close()\n\nprint(journal_cape_town)\n\n\n\n\n\nRead a multiple file and give which restaurants suitable for food if suitable for food give the food detailes\n\nfrom helper_functions import get_llm_response, print_llm_response\n\n\n\nfiles = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n\nfor file in files:\n\n# Read journal file for the city\n\nf = open(file, \"r\")\n\njournal = f.read()\n\nf.close()\n\n\n\n# Create prompt\n\nprompt = f\"\"\"Respond with \"Relevant to food\" or \"Not relevant to food\":if revelant mention what dish is special else visited another restaturant like this.  \n\nthe journal describes restaurants and their specialties \n\nJournal:\n\n{journal}\"\"\"\n\n\n\n# Use LLM to determine if the journal entry is useful\n\nprint(f\"{file} -> {get_llm_response(prompt)}\")\n\n\n\n\n\n\n\n\n\nfrom helper_functions import *\n\nfrom IPython.display import display, HTML\n\nfiles = [\"cape_town.txt\", \"istanbul.txt\", \"new_york.txt\", \"paris.txt\", \n\n\"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n\n\n\nfor file in files:\n\n#Open file and read contents\n\njournal_entry = read_journal(file)\n\n\n\n#Extract restaurants and display csv\n\nprompt = f\"\"\"\n\nExtract all restaurants, dishes, and chefs from the following journal entry.\n\nProvide the output in strict CSV format with columns:\n\n\n\nRestaurant,Dish,Chef\n\n\n\nRules:\n\nInclude headers exactly as above.\n\nIf the chef is not mentioned, write N/A.\n\nDo not include any markdown or extra explanations.\n\nKeep dish names as plain text (we will color them later in HTML).\n\nOutput only CSV rows.\n\n\n\nJournal entry:\n\n{journal_entry}\n\n\"\"\"\n\n\n\n\n\nprint(file)\n\nprint_llm_response(prompt)\n\nprint(\"\") # Prints a blank line!\n\n\n\nPrompt for hightlight the sentence:\n\nprompt = f\"\"\"\n\nGiven the following journal entry from a food critic, identify the \n\nrestaurants and their best dishes. Highlight and bold each restaurant \n\n(in orange) and best dish (in blue) within the original text. \n\n\n\nProvide the output as HTML suitable for display in a Jupyter notebook. \n\n\n\nJournal entry:\n\n{journal_tokyo}\n\n\"\"\"\n\nFor download the particular file\n\ndownload_file()\n\n\n\nCSV file:\n\nfrom helper_functions import get_llm_response, print_llm_response, display_table\n\nfrom IPython.display import Markdown\n\nimport csv\n\nf = open(\"itinerary.csv\", 'r')\n\ncsv_reader = csv.DictReader(f)\n\nitinerary = []\n\nfor row in csv_reader:\n\nprint(row)\n\nitinerary.append(row)\n\nf.close()\n\nprint(itinerary)\n\nprint(itinerary[0])\n\nprint(itinerary[0][\"Country\"])\n\ndisplay_table(itinerary)\n\n\n\nThe code opens the file itinerary.csv in read mode.\n\nIt uses csv.DictReader to read each row as a dictionary (key = column name, value = cell data).\n\nAll rows are collected into a list called itinerary.\n\nIt prints each row, the full list, and the first row.\n\nIt also shows how to access a specific value (Country from the first row).\n\nFinally, display_table(itinerary) displays the data neatly in table format.\n\n\n\nDisplay data based on condition\n\nfrom helper_functions import get_llm_response, print_llm_response, display_table\n\nfrom IPython.display import Markdown\n\nimport csv\n\nf = open(\"itinerary.csv\", 'r')\n\ncsv_reader = csv.DictReader(f)\n\nfiltered_data = []\n\n\n\n# Filter by country\n\nfor trip_stop in itinerary:\n\n# For example: get the destinations located in \"Japan\"\n\nif trip_stop[\"Country\"] == \"JAPAN\":\n\nfiltered_data.append(trip_stop)\n\ndisplay_table(filtered_data)\n\n\n\nOpens the CSV file (itinerary.csv).\n\nReads each row as a dictionary (column ‚Üí value).\n\nGoes through all rows one by one.\n\nSelects only the rows where \"Country\" is \"JAPAN\".\n\nSaves those rows into filtered_data.\n\nDisplays the filtered results as a table.\n\nwith open(\"itinerary.csv\", 'r') as f:\n\ncsv_reader = csv.DictReader(f)\n\nitinerary = list(csv_reader)  # Convert to a list\n\n\n\nif itinerary:  # Check if list is not empty\n\ntrip_stop = itinerary[1]  # Access the first item\n\ncity = trip_stop[\"City\"]\n\ncountry = trip_stop[\"Country\"]\n\narrival = trip_stop[\"Arrival\"]\n\ndeparture = trip_stop[\"Departure\"]\n\nprompt = f\"\"\"I will visit {city}, {country}, from {arrival} to {departure}. \n\nPlease create a detailed daily itinerary.\"\"\"\n\nprint(prompt)\n\nelse:\n\nprint(\"No data found in the CSV file.\"),\n\n\n\n\n\n\n\nwith open(\"itinerary.csv\", 'r') as f:       \n\ncsv_reader = csv.DictReader(f)          \n\nitinerary = list(csv_reader)            \n\n\n\nif itinerary:                               \n\ntrip_stop = itinerary[1]                \n\ncity = trip_stop[\"City\"]                \n\ncountry = trip_stop[\"Country\"]          \n\narrival = trip_stop[\"Arrival\"]          \n\ndeparture = trip_stop[\"Departure\"]      \n\nprompt = f\"\"\"I will visit {city}, {country}, from {arrival} to {departure}. \n\nPlease create a detailed daily itinerary.\"\"\"  \n\nprint(prompt)                           \n\nelse:\n\nprint(\"No data found in the CSV file.\") \n\nwith open(\"itinerary.csv\", 'r') as f:Opens the file itinerary.csv in read mode safely (auto closes when done).\n\ncsv.DictReader(f)Reads the CSV file row by row, turning each row into a dictionary.\n\nlist(csv_reader)Converts all rows into a list of dictionaries called itinerary.\n\nif itinerary:Checks if the CSV had any data (not empty).\n\ntrip_stop = itinerary[1]Takes the second row from the CSV (because indexing starts at 0).\n\n6‚Äì9. Extracts values from that row:\n\n\"City\" ‚Üí stored in city\n\n\"Country\" ‚Üí stored in country\n\n\"Arrival\" ‚Üí stored in arrival\n\n\"Departure\" ‚Üí stored in departure\n\nCreates a prompt sentence using those values.\n\nPrints the generated prompt.\n\nIf the CSV file is empty ‚Üí prints \"No data found in the CSV file.\"\n\n\n\n\n\n\n\nDefine functions for read and display the data in table format:\n\nimport csv\n\nfrom helper_functions import print_llm_response, get_llm_response, display_table\n\nfrom IPython.display import Markdown\n\n# The function called 'read_journal'\n\ndef read_journals(journal_file):\n\nf = open(journal_file, \"r\")\n\njournal = f.read() \n\nf.close()\n\n\n\n# Return the journal content\n\nreturn journal\n\n\n\njournal = read_journals(\"sydney.txt\")\n\n\n\nprint(journal)\n\nsydney_restaurants = read_csv(\"Sydney.csv\")\n\nfrom IPython.display import display, HTML\n\n\n\ndef display_table(data):\n\n\"\"\"\n\nDisplay a list of dictionaries as a HTML table.\n\nEach dictionary is a row, keys are column headers.\n\n\"\"\"\n\nif not data:\n\nprint(\"No data to display.\")\n\nreturn\n\n\n\n# Create table headers from the first dictionary\n\nheaders = data[0].keys()\n\n\n\n# Start HTML table\n\nhtml = \"<table border='1' style='border-collapse: collapse;'>\"\n\n\n\n# Add header row\n\nhtml += \"<tr>\"\n\nfor header in headers:\n\nhtml += f\"<th style='padding:5px; background-color:#f2f2f2;'>{header}</th>\"\n\nhtml += \"</tr>\"\n\n\n\n# Add data rows\n\nfor row in data:\n\nhtml += \"<tr>\"\n\nfor header in headers:\n\nhtml += f\"<td style='padding:5px;'>{row[header]}</td>\"\n\nhtml += \"</tr>\"\n\n\n\nhtml += \"</table>\"\n\n\n\n# Display the table\n\ndisplay(HTML(html))\n\nprint(\"----------------------\")\n\ndisplay_table(sydney_restaurants)\\\n\n\n\nOutput:\n\n\n\n\n\nModules 4:extending python with packages and api‚Äôs\n\n\n\n\n\nHelperfunction.py\n\n\n\n\n\nimport os\n\nfrom openai import OpenAI\n\nfrom dotenv import load_dotenv\n\n\n\nclient = None¬† # declare globally\n\n\n\n\n\ndef authenticate(api_key=None):\n\nglobal client\n\ntry:\n\n# Load environment variables from .env file\n\nload_dotenv('.env', override=True)\n\n\n\n# Get API key from environment\n\nopenai_api_key = os.getenv('OPENAI_API_KEY')\n\n\n\n# Use key from .env if available, else fallback to passed argument\n\nif openai_api_key:\n\nclient = OpenAI(api_key=openai_api_key)\n\nelif api_key:\n\nclient = OpenAI(api_key=api_key)\n\nelse:\n\nprint(\n\n\"¬†Warning: An OpenAI API key is required to use AI model functions.\\n\"\n\n\"Please provide the key by calling `authenticate(openai_api_key)` \"\n\n\"or ensure it is specified in the `.env` file as 'OPENAI_API_KEY'.\\n\"\n\n\"If you set it in the `.env` file, call `authenticate()` or reload the package to proceed.\"\n\n)\n\nreturn\n\n\n\nprint(\"Authentication successful!\")\n\n\n\nexcept Exception as e:\n\nprint(f\"¬†Authentication failed: {e}\")\n\n\n\n\n\n# Call function (no argument means it will try to read from .env)\n\nauthenticate()\n\ndef print_llm_response(prompt):\n\n\"\"\"\n\nThis function takes a prompt (a string),\n\nsends it to OpenAI's GPT-4o-mini model,\n\nand prints the model's response.\n\n\"\"\"\n\ntry:\n\n# Validate input type\n\nif not isinstance(prompt, str):\n\nraise ValueError(\"Input must be a string enclosed in quotes.\")\n\n\n\n# Send request to OpenAI model\n\ncompletion = client.chat.completions.create(\n\nmodel=\"gpt-4o-mini\",\n\nmessages=[\n\n{\"role\": \"system\", \"content\": \"You are a helpful but terse AI assistant who gets straight to the point.\"},\n\n{\"role\": \"user\", \"content\": prompt}\n\n],\n\ntemperature=0.0 # deterministic output\n\n)\n\n\n\n# Extract response from model\n\nresponse = completion.choices[0].message.content\n\nprint(response)\n\n\n\nexcept Exception as e:\n\nprint(\"Error:\", str(e))\n\ndef get_llm_response(prompt):\n\n\"\"\"\n\nThis function takes a prompt (a string),\n\nsends it to OpenAI's GPT-4o-mini model,\n\nand returns the response as a string.\n\n\"\"\"\n\ntry:\n\nif not isinstance(prompt, str):\n\nraise ValueError(\"Input must be a string enclosed in quotes.\")\n\n\n\ncompletion = client.chat.completions.create(\n\nmodel=\"gpt-4o-mini\",\n\nmessages=[\n\n{\"role\": \"system\", \"content\": \"You are a helpful but terse AI assistant who gets straight to the point.\"},\n\n{\"role\": \"user\", \"content\": prompt}\n\n],\n\ntemperature=0.0\n\n)\n\n\n\nresponse = completion.choices[0].message.content\n\nreturn response\n\n\n\nexcept Exception as e:\n\nreturn f\"Error: {str(e)}\"\n\n\n\n\n\ndef cels_to_fahrenheit(celsius):\n\n\"\"\"\n\nConvert Celsius temperature to Fahrenheit\n\nand print the result.\n\n\"\"\"\n\nfahrenheit = (celsius * 9/5) + 32\n\nprint(f\"{celsius}¬∞C is equivalent to {fahrenheit:.2f}¬∞F\")\n\n\n\n\n\nfrom helper_functions import *\n\nprint_llm_response(\"who is the prime minister of india today\")\n\nprint(celsius_to_fahrenheit(30))\n\nget=get_llm_response(\"father of science\")\n\nprint(get)\n\nOutput:\n\n\n\n\n\n\n\nMath Package\n\nFunctions like cos, sin, tan, pi, floor trigonometry and rounding.\n\nExample 1: Cosine\n\nfrom math import cos, pi\n\n\n\n# Calculate cosine of pi/2\n\nprint(cos(pi/2))  # Output: 0.0\n\nExample 2: Floor\n\nfrom math import floor\n\n\n\n# Round down a number\n\nprint(floor(5.7))  # Output: 5\n\nExample 3: Tangent\n\nfrom math import tan\n\n\n\nvalues = [0, pi/4, pi/2]\n\nfor value in values:\n\nprint(f\"Tangent of {value:.2f} is {tan(value)}\")\n\n\n\nStatistics Package\n\nFunctions like mean, median, stdev help calculate average and spread of data.\n\nExample 1: Mean\n\nfrom statistics import mean\n\n\n\nheights = [160, 172, 155]\n\nprint(mean(heights))  # Output: 162.33\n\nExample 2: Standard Deviation\n\nfrom statistics import stdev\n\n\n\nprint(stdev(heights))  # Output: 8.5\n\nExample 3: Median\n\nfrom statistics import median\n\n\n\nscores = [28, 14, 15, 25, 21]\n\nprint(median(scores))  # Output: 21\n\n\n\nRandom Package\n\nFunctions like sample or randint generate random numbers or select random items from a list.\n\nExample 1: Random Sample\n\nfrom random import sample\n\n\n\nspices = [\"cumin\", \"turmeric\", \"oregano\", \"paprika\"]\n\nprint(sample(spices, 2))  # Output: ['oregano', 'cumin'] (random)\n\nExample 2: Random Integer\n\nfrom random import randint\n\n\n\nprint(randint(1, 10))  # Output: random number between 1 and 10\n\n\n\nUsing LLM with Random Ingredients\n\ncombine random selections with an LLM to generate recipes.\n\nExample:\n\nfrom random import sample\n\nfrom helper_functions import get_llm_response\n\n\n\nspices = [\"cumin\", \"turmeric\", \"oregano\", \"paprika\"]\n\nvegetables = [\"lettuce\", \"tomato\", \"carrot\", \"broccoli\"]\n\nproteins = [\"chicken\", \"tofu\", \"beef\", \"fish\"]\n\n\n\n# Randomly select ingredients\n\nrandom_spices = sample(spices, 2)\n\nrandom_vegetables = sample(vegetables, 2)\n\nrandom_protein = sample(proteins, 1)\n\n\n\n# Create prompt\n\nprompt = f\"\"\"Please suggest a recipe using:\n\nSpices: {random_spices}\n\nVegetables: {random_vegetables}\n\nProteins: {random_protein}\"\"\"\n\n\n\n# Generate recipe from LLM\n\nrecipe = get_llm_response(prompt)\n\nprint(recipe)\n\n\n\nThird party package\n\n\n\nPandas = Python + Excel-like tables\n\nDataFrame = table, Series = column\n\nUse Pandas for reading, analyzing, filtering, and saving structured data\n\nMain Use of Pandas\n\nPandas is mainly used for working with structured data (like tables).\n\nYou can use it to:\n\nRead and write data ‚Äì from CSV, Excel, JSON, SQL, etc.\n\nAnalyze data ‚Äì calculate averages, sums, max/min, counts, etc.\n\nClean data ‚Äì remove duplicates, fill missing values, filter rows.\n\nManipulate data ‚Äì sort, group, merge, or transform columns.\n\nPrepare data ‚Äì for machine learning, visualization, or reports.\n\nHow to Use Pandas (Basic Steps)\n\nInstall and Import\n\npip install pandas\n\nimport pandas as pd\n\nRead a CSV File\n\ndf = pd.read_csv(\"data.csv\")  # Load CSV into a DataFrame\n\nView Data\n\nprint(df.head())      # Show first 5 rows\n\nprint(df.columns)     # Show column names\n\nAccess Columns and Rows\n\nprint(df['Name'])     # Access column 'Name'\n\nprint(df.iloc[0])     # Access first row\n\nFilter Data\n\nadults = df[df['Age'] > 18]   # Only rows where Age > 18\n\nBasic Analysis\n\nprint(df['Age'].mean())       # Average age\n\nprint(df['Salary'].max())     # Maximum salary\n\nSave to CSV\n\ndf.to_csv(\"filtered_data.csv\", index=False)\n\nexample:\n\n\n\nimport pandas as pd\n\ndata = pd.read_csv('car_data.csv')\n\nprint(data.head())      # Show first 5 rows\n\nprint(data.columns) \n\nprint(data['Price'])\n\nprint(data.iloc[0])\n\nprint(data[data['Price'] > 12550])   \n\nprint(data['Price'].mean())      \n\nprint(data['Price'].max())\n\n\n\nWhat is Matplotlib?\n\nMatplotlib is a third-party Python library for data visualization.\n\nIt helps you create graphs, charts, and plots from your data.\n\nVery useful for exploring data and presenting results.\n\n\n\n2Ô∏è‚É£ Main Uses\n\nLine plots ‚Äì to show trends over time.\n\nBar charts ‚Äì to compare quantities.\n\nScatter plots ‚Äì to show relationships between variables.\n\nHistograms ‚Äì to show distribution of data.\n\nCustom plots ‚Äì colors, labels, titles, and legends\n\n# Note the .pyplot\n\nimport matplotlib.pyplot as plt\n\nplt.plot(data[\"Kilometer\"], data[\"Price\"]) \n\nplt.title(\"Line Plot Example\")   # Add title\n\nplt.xlabel(\"X-axis\")             # X-axis label\n\nplt.ylabel(\"Y-axis\")  \n\nplt.grid()# Y-axis label\n\nplt.show()   \n\nprint(\"----------\")\n\n# Display the bar# Create line plot\n\nplt.bar(data[\"Kilometer\"], data[\"Price\"]) \n\nplt.title(\"Line Plot Example\")   # Add title\n\nplt.xlabel(\"X-axis\")             # X-axis label\n\nplt.ylabel(\"Y-axis\")  \n\nplt.grid()\n\n# Y-axis label\n\nplt.show()     \n\n# Display the plot# Create line plot\n\nplt.scatter(data[\"Kilometer\"], data[\"Price\"]) \n\nplt.title(\"Line Plot Example\")   # Add title\n\nplt.xlabel(\"X-axis\")             # X-axis label\n\nplt.ylabel(\"Y-axis\") \n\nplt.grid(True)\n\nplt.show()   \n\nprint(\"----------\")\n\nplt.hist(data[\"Price\"], bins=5, color='green')\n\nplt.title(\"Price Distribution\")\n\nplt.grid(True)\n\nplt.show()\n\n\n\nBeautifulSoup (bs4)\n\nPurpose: bs4 (BeautifulSoup version 4) is a Python library for web scraping.\n\nUse: It helps you extract data from HTML or XML files, like text, links, tables, or images.\n\nWorks With: Usually used with requests to fetch web pages from the internet.\n\n# The url from one of the Batch's newsletter\n\nurl = 'https://www.deeplearning.ai/the-batch/the-world-needs-more-intelligence/'\n\n\n\n# Getting the content from the webpage's contents\n\nresponse = requests.get(url)\n\n\n\n# Print the response from the requests\n\nprint(response)\n\nHTML(f'<iframe src={url} width=\"60%\" height=\"400\"></iframe>')\n\n# Using beautifulsoup to extract the text\n\nsoup = BeautifulSoup(response.text, 'html.parser')\n\n# Find all the text in paragraph elements on the webpage\n\nall_text = soup.find_all('h1')\n\n\n\n# Create an empty string to store the extracted text\n\ncombined_text = \"\"\n\n\n\n# Iterate over 'all_text' and add to the combined_text string\n\nfor text in all_text:\n\ncombined_text = combined_text + \"\\n\" + text.get_text()\n\n\n\n# Print the final combined text\n\nprint(combined_text)\n\nprompt = f\"\"\"Extract the key bullet points from the following text.\n\n\n\nText:\n\n{combined_text}\n\n\"\"\"\n\nprint_llm_response(prompt)\n\n\n\nOutput:\n\n<Response [200]>\n\n\n\nThe World Needs More Intelligence Human intelligence is expensive, artificial intelligence is cheap. To solve big problems like climate change, it makes sense to double down on AI.\n\nHuman intelligence is expensive.\n\nArtificial intelligence is cheap.\n\nAI can help solve big problems like climate change.\n\nEmphasis on increasing investment in AI.\n\nAisetup packages:\n\nThe aisetup package is designed to make it easier to interact with LLMs (like OpenAI GPT models).\n\nFunction\n\nPurpose\n\nExample\n\nget_llm_response(prompt)\n\nSends a text prompt to the LLM and returns the generated response.\n\npython\\nfrom aisetup import get_llm_response\\nresponse = get_llm_response(\"Why is Python easy?\")\\nprint(response)\n\nprint_llm_response(prompt)\n\nSends a text prompt to the LLM and prints the response directly.\n\npython\\nfrom aisetup import print_llm_response\\nprint_llm_response(\"Who is the sports minister of Tamil Nadu?\")\n\n!pip install aisetup\n\nfrom aisetup import get_llm_response,print_llm_response,display_table\n\nr=get_llm_response(\"why python easy\")\n\nprint(r)\n\nprint_llm_response(\"who is the sports minister of tamil nadu\")\n\noutput: Requirement already satisfied: aisetup in /usr/local/lib/python3.9/site-packages (0.1.4)\n\nRequirement already satisfied: folium<0.18.0,>=0.17.0 in /usr/local/lib/python3.9/site-packages (from aisetup) (0.17.0)\n\nRequirement already satisfied: ipython==8.18.1 in /usr/local/lib/python3.9/site-packages (from aisetup) (8.18.1)\n\nRequirement already satisfied: ipywidgets<9.0.0,>=8.1.3 in /usr/local/lib/python3.9/site-packages (from aisetup) (8.1.5)\n\nRequirement already satisfied: matplotlib<4.0.0,>=3.9.2 in /usr/local/lib/python3.9/site-packages (from aisetup) (3.9.2)\n\nRequirement already satisfied: numpy==2.0.1 in /usr/local/lib/python3.9/site-packages (from aisetup) (2.0.1)\n\nRequirement already satisfied: openai<2.0.0,>=1.42.0 in /usr/local/lib/python3.9/site-packages (from aisetup) (1.93.0)\n\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.9/site-packages (from aisetup) (1.0.1)\n\nRequirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.9/site-packages (from aisetup) (2.32.4)\n\nRequirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (5.1.1)\n\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (0.19.1)\n\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (0.1.7)\n\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (3.0.43)\n\nRequirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (2.17.2)\n\nRequirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (0.6.3)\n\nRequirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (5.9.0)\n\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (4.11.0)\n\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (1.2.2)\n\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython==8.18.1->aisetup) (4.9.0)\n\nRequirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.9/site-packages (from folium<0.18.0,>=0.17.0->aisetup) (0.8.1)\n\nRequirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.9/site-packages (from folium<0.18.0,>=0.17.0->aisetup) (3.1.4)\n\nRequirement already satisfied: xyzservices in /usr/local/lib/python3.9/site-packages (from folium<0.18.0,>=0.17.0->aisetup) (2025.4.0)\n\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.9/site-packages (from ipywidgets<9.0.0,>=8.1.3->aisetup) (0.2.2)\n\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.9/site-packages (from ipywidgets<9.0.0,>=8.1.3->aisetup) (4.0.13)\n\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.9/site-packages (from ipywidgets<9.0.0,>=8.1.3->aisetup) (3.0.13)\n\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.9.2->aisetup) (1.3.0)\n\n [notice] A new release of pip is available: 24.0 -> 25.2\n\n[notice] To update, run: pip install --upgrade pip\n\nPython is considered easy due to its simple syntax, readability, and extensive libraries. It allows for quick learning and rapid development, making it accessible for beginners and efficient for experienced programmers.\n\npython-dotenv\n\nThe package is installed as:\n\npip install python-dotenv\n\nIt allows store sensitive data like API keys, passwords, or configuration settings in a .env file instead of hardcoding them in your scripts.\n\n\n\nThis keeps your code secure and portable.\n\n# Install required packages (run only once)\n\n!pip install geocoder requests\n\n\n\nimport geocoder\n\nimport requests\n\n\n\ndef get_feels_like_temperature(api_key):\n\nif not api_key:\n\nprint(\" API key not provided.\")\n\nreturn\n\n\n\n# Get current location\n\ng = geocoder.ip('me')\n\nif not g.ok:\n\nprint(\" Could not detect location.\")\n\nreturn\n\n\n\nlat, lon = g.latlng\n\nprint(f\"Detected Latitude: {lat}, Longitude: {lon}\")\n\n\n\n# Use the \"weather\" endpoint for current temperature\n\nurl = f\"https://api.openweathermap.org/data/2.5/weather?units=metric&lat={lat}&lon={lon}&appid={api_key}\"\n\n\n\n# Make API request\n\nresponse = requests.get(url)\n\nif response.status_code != 200:\n\nprint(f\" Error fetching weather data: {response.status_code}\")\n\nprint(response.text)  # Show API error message\n\nreturn\n\n\n\ndata = response.json()\n\nfeels_like = data['main']['feels_like']\n\ncity = data['name']\n\n\n\nprint(f\" The temperature currently feels like {feels_like}¬∞C in {city}.\")\n\n\n\n# Call the function with your API key\n\nget_feels_like_temperature(\"xyxsddfff\")\n\nOpenAi:\n\nThe openai package is the official Python client library provided by OpenAI.It allows you to connect your Python programs to OpenAI‚Äôs models like GPT (ChatGPT), DALL¬∑E, Whisper, and Embeddings through API calls.\n\nimport os\n\nfrom dotenv import load_dotenv\n\nfrom openai import OpenAI\n\n\n\n# Load environment variables from .env file\n\nload_dotenv('.env', override=True)\n\n\n\n# Get API key from environment\n\nopenai_api_key = os.getenv('OPENAI_API_KEY')\n\n\n\n# Initialize OpenAI client\n\nclient = OpenAI(api_key=openai_api_key)\n\n\n\n# Function to get LLM response\n\ndef get_llm_response(prompt: str) -> str:\n\ncompletion = client.chat.completions.create(\n\nmodel=\"gpt-4o-mini\",\n\nmessages=[\n\n{\n\n\"role\": \"system\",\n\n\"content\": \"You are a helpful but terse AI assistant who gets straight to the point.\",\n\n},\n\n{\"role\": \"user\", \"content\": prompt},\n\n],\n\ntemperature=0.0,\n\n)\n\nresponse = completion.choices[0].message.content\n\nreturn response\n\n\n\n# Example usage\n\nprint(get_llm_response(\"Who are you? Who is the president of India?\"))\n\nwhen temperature change I content also changed\n\nResources:LLm create \n\nBeginner‚Äôs Guide to OpenAI API. Build your own LLM tool from scratch | by Chanin Nantasenamat | Data Professor | Medium\n\n\n\n\n\n\n\n",
    "detectedPatterns": [
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value",
      "key-value"
    ],
    "keyValuePairs": {
      "Course Name": "AI Python for Beginners",
      "print(f\"The addition of a + b is {a+b}\")  # Output": "The addition of a + b is 30",
      "print(f\"Pi": "{pi:.2f}\")   # Pi: 3.14",
      "print(f\"Number": "{num:,}\") # Number: 12,345",
      "print(f\"{age=}\")  # Output": "age=30",
      "Examples": "",
      "override=True means": "If there's already an environment variable, replace it with the one in .env.",
      "def get_llm_response(prompt": "str) -> str:",
      "system": "sets the behavior of the AI (e.g., ‚ÄúBe helpful and short‚Äù)",
      "user": "the prompt you entered",
      "temperature=0.0": "means ‚Äúgive me factual, consistent answers‚Äù (no creativity)",
      "role": "who is speaking (system, user, or assistant)",
      "content": "what they are saying (the actual text)",
      "Purpose": "bs4 (BeautifulSoup version 4) is a Python library for web scraping.",
      "Module 2": "Automating Task with Python:",
      "Output": "[1, 2, 3, 4]",
      "prompt=f\"\"\"decribe about the sports and marketing for this sports to join Sports": "{list}\"\"\"",
      "\"Mint Chocolate Chip\"": "\"Refreshing mint ice cream studded with decadent chocolate chips.\",",
      "\"Cookie Dough\"": "\"Vanilla ice cream loaded with chunks of chocolate chip cookie dough.\",",
      "\"Salted Caramel\"": "\"Sweet and salty with a smooth caramel swirl and a hint of sea salt.\"",
      "print(\" Ice Cream Flavors (Keys)": "\")",
      "\"high_priority\"": "high_priority_tasks,",
      "\"medium_priority\"": "medium_priority_tasks,",
      "\"low_priority\"": "low_priority_tasks",
      "task=[{\"description\"": "\"Write a email to manager about task completed details\",\"time\":5},{\"description\":\"Write a email to hr about task planned leave details\",\"time\":10},{\"description\":\"content for ai with python course\",\"time\":5}]",
      "Module3": "Working with data and spreadsheet in Ai",
      "with open(\"email.txt\", \"r\") as f": "# <-- start of context block",
      "Inside the block": "read the file safely.",
      "After the block": "Python automatically closes the file (f.close() happens ).",
      "Above three not predefined functions in python": "my_project/",
      "print(\"\\nLLM Response": "\\n\" + response + \"\\n\")",
      "# Example": "create 'email.txt' in your project folder with some text",
      "print(\"Files in folder": "\", files)",
      "prompt = f\"\"\"Respond with \"Relevant to food\" or \"Not relevant to food\"": "if revelant mention what dish is special else visited another restaturant like this.",
      "# For example": "get the destinations located in \"Japan\"",
      "if itinerary": "Checks if the CSV had any data (not empty).",
      "with open(\"itinerary.csv\", 'r') as f": "Opens the file itinerary.csv in read mode safely (auto closes when done).",
      "html = \"<table border='1' style='border-collapse": "collapse;'>\"",
      "html += f\"<th style='padding": "5px; background-color:#f2f2f2;'>{header}</th>\"",
      "html += f\"<td style='padding": "5px;'>{row[header]}</td>\"",
      "Modules 4": "extending python with packages and api‚Äôs",
      "\"¬†Warning": "An OpenAI API key is required to use AI model functions.\\n\"",
      "print(f\"¬†Authentication failed": "{e}\")",
      "{\"role\"": "\"user\", \"content\": prompt},",
      "print(\"Error": "\", str(e))",
      "return f\"Error": "{str(e)}\"",
      "print(f\"{celsius}¬∞C is equivalent to {fahrenheit": ".2f}¬∞F\")",
      "Example 1": "Random Sample",
      "print(cos(pi/2))  # Output": "0.0",
      "Example 2": "Random Integer",
      "print(floor(5.7))  # Output": "5",
      "Example 3": "Median",
      "print(f\"Tangent of {value": ".2f} is {tan(value)}\")",
      "print(mean(heights))  # Output": "162.33",
      "print(stdev(heights))  # Output": "8.5",
      "print(median(scores))  # Output": "21",
      "print(sample(spices, 2))  # Output": "['oregano', 'cumin'] (random)",
      "print(randint(1, 10))  # Output": "random number between 1 and 10",
      "Spices": "{random_spices}",
      "Vegetables": "{random_vegetables}",
      "Proteins": "{random_protein}\"\"\"",
      "Use": "It helps you extract data from HTML or XML files, like text, links, tables, or images.",
      "Works With": "Usually used with requests to fetch web pages from the internet.",
      "url = 'https": "//www.deeplearning.ai/the-batch/the-world-needs-more-intelligence/'",
      "output": "Requirement already satisfied: aisetup in /usr/local/lib/python3.9/site-packages (0.1.4)",
      "Requirement already satisfied": "contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.9.2->aisetup) (1.3.0)",
      "[notice] A new release of pip is available": "24.0 -> 25.2",
      "[notice] To update, run": "pip install --upgrade pip",
      "print(f\"Detected Latitude": "{lat}, Longitude: {lon}\")",
      "url = f\"https": "//api.openweathermap.org/data/2.5/weather?units=metric&lat={lat}&lon={lon}&appid={api_key}\"",
      "print(f\" Error fetching weather data": "{response.status_code}\")",
      "\"role\"": "\"system\",",
      "\"content\"": "\"You are a helpful but terse AI assistant who gets straight to the point.\",",
      "Resources": "LLm create"
    }
  }
}